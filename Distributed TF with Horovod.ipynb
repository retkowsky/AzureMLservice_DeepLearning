{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed TensorFlow with Horovod\n",
    "In this tutorial, you will train a word2vec model in TensorFlow using distributed training via [Horovod](https://github.com/uber/horovod)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Horovod is a distributed training framework for TensorFlow, Keras, PyTorch, and MXNet. The goal of Horovod is to make distributed Deep Learning fast and easy to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://docs.microsoft.com/en-us/azure/machine-learning/service/media/overview-what-is-azure-ml/aml.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The TensorFlow estimator also supports distributed training across CPU and GPU clusters. You can easily run distributed TensorFlow jobs and Azure Machine Learning will manage the orchestration for you.\n",
    "\n",
    "Azure Machine Learning supports two methods of distributed training in TensorFlow:\n",
    "\n",
    "1. **MPI-based distributed training** using the **Horovod** framework\n",
    "2. **Native distributed TensorFlow** using the parameter server method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GPU optimized VM sizes are specialized virtual machines** available with single or multiple NVIDIA GPUs. These sizes are designed for compute-intensive, graphics-intensive, and visualization workloads. This article provides information about the number and type of GPUs, vCPUs, data disks, and NICs. Storage throughput and network bandwidth are also included for each size in this grouping.\n",
    "\n",
    "- **NC, NCv2, NCv3** sizes are optimized for compute-intensive and network-intensive applications and algorithms. Some examples are CUDA- and OpenCL-based applications and simulations, AI, and Deep Learning. The NCv3-series is focused on high-performance computing workloads featuring NVIDIA’s Tesla V100 GPU. The NC-series uses the Intel Xeon E5-2690 v3 2.60GHz v3 (Haswell) processor, and the NCv2-series and NCv3-series VMs use the Intel Xeon E5-2690 v4 (Broadwell) processor.\n",
    "\n",
    "- **ND, and NDv2** The ND-series is focused on training and inference scenarios for deep learning. It uses the NVIDIA Tesla P40 GPU and the Intel Xeon E5-2690 v4 (Broadwell) processor. The NDv2-series uses the Intel Xeon Platinum 8168 (Skylake) processor.\n",
    "\n",
    "- **NV and NVv3** sizes are optimized and designed for remote visualization, streaming, gaming, encoding, and VDI scenarios using frameworks such as OpenGL and DirectX. These VMs are backed by the NVIDIA Tesla M60 GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://docs.microsoft.com/en-us/azure/architecture/reference-architectures/ai/_images/distributed_dl_flow.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.6.9 |Anaconda, Inc.| (default, Jul 30 2019, 19:07:31) \\n[GCC 7.3.0]'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-13 09:13:31.348033\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "print(now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure ML service version =  1.0.72\n"
     ]
    }
   ],
   "source": [
    "# Check core SDK version number\n",
    "import azureml.core\n",
    "\n",
    "print(\"Azure ML service version = \", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Connexion Azure ML service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "#Workspace\n",
    "import os\n",
    "subscription_id = os.environ.get(\"SUBSCRIPTION_ID\", \"70b8f39e-8863-49f7-b6ba-34a80799550c\")\n",
    "resource_group = os.environ.get(\"RESOURCE_GROUP\", \"azuremlserviceresourcegroup\")\n",
    "workspace_name = os.environ.get(\"WORKSPACE_NAME\", \"azuremlservice\")\n",
    "\n",
    "\n",
    "from azureml.core import Workspace\n",
    "try:\n",
    "   ws = Workspace(subscription_id = subscription_id, resource_group = resource_group, workspace_name = workspace_name)\n",
    "   ws.write_config()\n",
    "   print(\"OK\")\n",
    "except:\n",
    "   print(\"Error: Workspace not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workspace name: azuremlservice\n",
      "Azure region: westeurope\n",
      "Resource group: azuremlserviceresourcegroup\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.workspace import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Resource group: ' + ws.resource_group, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create or Attach existing AmlCompute\n",
    "You will need to create a [compute target](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#compute-target) for training your model. In this tutorial, you create `AmlCompute` as your training compute resource.\n",
    "\n",
    "**Creation of AmlCompute takes approximately 5 minutes.** If the AmlCompute with that name is already in your workspace this code will skip the creation process.\n",
    "\n",
    "As with other Azure services, there are limits on certain resources (e.g. AmlCompute) associated with the Azure Machine Learning service. Please read [this article](https://docs.microsoft.com/azure/machine-learning/service/how-to-manage-quotas) on the default limits and how to request more quota."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Standard_NC6 :\n",
    "6 vCPU - 56 Gb Ram - 340 GB SSD - 1 GPU- 12 Gb GPU Memory**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> https://docs.microsoft.com/en-us/azure/virtual-machines/windows/sizes-gpu<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing compute target\n",
      "{'currentNodeCount': 0, 'targetNodeCount': 0, 'nodeStateCounts': {'preparingNodeCount': 0, 'runningNodeCount': 0, 'idleNodeCount': 0, 'unusableNodeCount': 0, 'leavingNodeCount': 0, 'preemptedNodeCount': 0}, 'allocationState': 'Steady', 'allocationStateTransitionTime': '2019-11-13T07:59:19.867000+00:00', 'errors': None, 'creationTime': '2019-11-12T15:26:15.321861+00:00', 'modifiedTime': '2019-11-12T15:26:31.231689+00:00', 'provisioningState': 'Succeeded', 'provisioningStateTransitionTime': None, 'scaleSettings': {'minNodeCount': 0, 'maxNodeCount': 4, 'nodeIdleTimeBeforeScaleDown': 'PT120S'}, 'vmPriority': 'Dedicated', 'vmSize': 'STANDARD_NC6'}\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# choose a name for your cluster\n",
    "cluster_name = \"gpu-cluster\"\n",
    "\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing compute target')\n",
    "except ComputeTargetException:\n",
    "    print('Creating a new compute target...')\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_NC6', \n",
    "                                                           max_nodes=4)\n",
    "\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "\n",
    "    compute_target.wait_for_completion(show_output=True)\n",
    "\n",
    "# use get_status() to get a detailed status for the current cluster. \n",
    "print(compute_target.get_status().serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code creates a GPU cluster. If you instead want to create a CPU cluster, provide a different VM size to the `vm_size` parameter, such as `STANDARD_D2_V2`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create a Dataset for Files\n",
    "A Dataset can reference single or multiple files in your datastores or public urls. The files can be of any format. FileDataset provides you with the ability to download or mount the files to your compute. By creating a dataset, you create a reference to the data source location. The data remains in its existing location, so no extra storage cost is incurred. [Learn More](https://aka.ms/azureml/howto/createdatasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Dataset\n",
    "\n",
    "web_paths = ['http://mattmahoney.net/dc/text8.zip']\n",
    "dataset = Dataset.File.from_files(path=web_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may want to register datasets using the register() method to your workspace so that the dataset can be shared with others, reused across various experiments, and referred to by name in your training script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.register(workspace=ws,\n",
    "                           name='mattmahoney dataset',\n",
    "                           description='mattmahoney training and test dataset',\n",
    "                           create_new_version=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['/text8.zip'], dtype=object)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list the files referenced by the dataset\n",
    "dataset.to_path()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train model on the remote compute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Create a project directory\n",
    "Create a directory that will contain all the necessary code from your local machine that you will need access to on the remote resource. This includes the training script, and any additional files your training script depends on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "project_folder = './tf-distr-hvd'\n",
    "os.makedirs(project_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy the training script `tf_horovod_word2vec.py` into this project directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./tf-distr-hvd/tf_horovod_word2vec.py'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "shutil.copy('tf_horovod_word2vec.py', project_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Create an experiment\n",
    "Create an [Experiment](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#experiment) to track all the runs in your workspace for this distributed TensorFlow tutorial. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "\n",
    "experiment_name = 'TF-horovod'\n",
    "experiment = Experiment(ws, name=experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Create a TensorFlow estimator\n",
    "The AML SDK's TensorFlow estimator enables you to easily submit TensorFlow training jobs for both single-node and distributed runs. For more information on the TensorFlow estimator, refer [here](https://docs.microsoft.com/azure/machine-learning/service/how-to-train-tensorflow).\n",
    "\n",
    "The TensorFlow estimator also takes a `framework_version` parameter -- if no version is provided, the estimator will default to the latest version supported by AzureML. Use `TensorFlow.get_supported_versions()` to get a list of all versions supported by your current SDK version or see the [SDK documentation](https://docs.microsoft.com/en-us/python/api/azureml-train-core/azureml.train.dnn?view=azure-ml-py) for the versions supported in the most current release."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Horovod is an open-source framework for distributed training developed by Uber. It offers an easy path to distributed GPU TensorFlow jobs.\n",
    "\n",
    "To use Horovod, specify an MpiConfiguration object for the distributed_training parameter in the TensorFlow constructor. This parameter ensures that Horovod library is installed for you to use in your training script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.dnn import TensorFlow, Mpi\n",
    "\n",
    "script_params={\n",
    "    '--input_data': dataset.as_named_input('mattmahoney').as_mount(),\n",
    "}\n",
    "\n",
    "estimator= TensorFlow(source_directory=project_folder,\n",
    "                      compute_target=compute_target,\n",
    "                      script_params=script_params,\n",
    "                      entry_script='tf_horovod_word2vec.py',\n",
    "                      node_count=2,\n",
    "                      distributed_training=Mpi(),\n",
    "                      framework_version='1.13', \n",
    "                      use_gpu=True,\n",
    "                      pip_packages=['azureml-dataprep[pandas,fuse]'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code specifies that we will run our training script on `2` nodes, with one worker per node. In order to execute a distributed run using MPI/Horovod, you must provide the argument `distributed_backend=Mpi()`. To specify `i` workers per node, you must provide the argument `distributed_backend=Mpi(process_count_per_node=i)`. Using this estimator with these settings, TensorFlow, Horovod and their dependencies will be installed for you. However, if your script also uses other packages, make sure to install them via the `TensorFlow` constructor's `pip_packages` or `conda_packages` parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Submit job\n",
    "Run your experiment by submitting your estimator object. Note that this call is asynchronous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run(Experiment: TF-horovod,\n",
      "Id: TF-horovod_1573636453_7e86d133,\n",
      "Type: azureml.scriptrun,\n",
      "Status: Starting)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'TF-horovod_1573636453_7e86d133',\n",
       " 'target': 'gpu-cluster',\n",
       " 'status': 'Queued',\n",
       " 'properties': {'_azureml.ComputeTargetType': 'batchai',\n",
       "  'ContentSnapshotId': 'a61d8890-9078-4e00-913d-4b143e7b2b58',\n",
       "  'AzureML.DerivedImageName': 'azureml/azureml_75651667c3311d0b90ca821953173db3',\n",
       "  'ProcessInfoFile': 'azureml-logs/process_info.json',\n",
       "  'ProcessStatusFile': 'azureml-logs/process_status.json'},\n",
       " 'inputDatasets': [{'dataset': {'id': '113c9925-6a23-467e-8106-8a7c0ce308a4'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'mattmahoney', 'mechanism': 'Mount'}}],\n",
       " 'runDefinition': {'script': 'tf_horovod_word2vec.py',\n",
       "  'arguments': ['--input_data', 'DatasetConsumptionConfig:mattmahoney'],\n",
       "  'sourceDirectoryDataStore': 'workspaceblobstore',\n",
       "  'framework': 'Python',\n",
       "  'communicator': 'Mpi',\n",
       "  'target': 'gpu-cluster',\n",
       "  'dataReferences': {'workspaceblobstore': {'dataStoreName': 'workspaceblobstore',\n",
       "    'mode': 'Mount',\n",
       "    'pathOnDataStore': None,\n",
       "    'pathOnCompute': None,\n",
       "    'overwrite': False}},\n",
       "  'data': {'mattmahoney': {'dataLocation': {'dataset': {'id': '113c9925-6a23-467e-8106-8a7c0ce308a4'},\n",
       "     'dataPath': None},\n",
       "    'createOutputDirectories': False,\n",
       "    'mechanism': 'Mount',\n",
       "    'environmentVariableName': 'mattmahoney',\n",
       "    'pathOnCompute': None,\n",
       "    'overwrite': False}},\n",
       "  'jobName': None,\n",
       "  'maxRunDurationSeconds': None,\n",
       "  'nodeCount': 2,\n",
       "  'environment': {'name': 'Experiment TF-horovod Environment',\n",
       "   'version': 'Autosave_2019-11-13T07:39:51Z_13a6a328',\n",
       "   'python': {'interpreterPath': 'python',\n",
       "    'userManagedDependencies': False,\n",
       "    'condaDependencies': {'channels': ['conda-forge'],\n",
       "     'dependencies': ['python=3.6.2',\n",
       "      {'pip': ['azureml-dataprep[pandas,fuse]',\n",
       "        'azureml-defaults',\n",
       "        'tensorflow-gpu==1.13.1',\n",
       "        'horovod==0.16.1']}],\n",
       "     'name': 'azureml_87bf8b18f50c3819153ad5fad9efbcd9'},\n",
       "    'baseCondaEnvironment': None},\n",
       "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'docker': {'baseImage': 'mcr.microsoft.com/azureml/base-gpu:intelmpi2018.3-cuda10.0-cudnn7-ubuntu16.04',\n",
       "    'baseDockerfile': None,\n",
       "    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n",
       "    'enabled': True,\n",
       "    'arguments': []},\n",
       "   'spark': {'repositories': [], 'packages': [], 'precachePackages': False},\n",
       "   'inferencingStackVersion': None},\n",
       "  'history': {'outputCollection': True,\n",
       "   'directoriesToWatch': ['logs'],\n",
       "   'snapshotProject': True},\n",
       "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'amlCompute': {'name': None,\n",
       "   'vmSize': None,\n",
       "   'retainCluster': False,\n",
       "   'clusterMaxNodeCount': 2},\n",
       "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
       "  'mpi': {'processCountPerNode': 1},\n",
       "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
       "  'containerInstance': {'region': None, 'cpuCores': 2, 'memoryGb': 3.5},\n",
       "  'exposedPorts': None,\n",
       "  'docker': {'useDocker': True,\n",
       "   'sharedVolumes': True,\n",
       "   'shmSize': '2g',\n",
       "   'arguments': []}},\n",
       " 'logFiles': {}}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run = experiment.submit(estimator)\n",
    "print(run)\n",
    "run.get_details()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 Monitor your run\n",
    "You can monitor the progress of the run with a Jupyter widget. Like the run submission, the widget is asynchronous and provides live updates every 10-15 seconds until the job completes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ba315668c2d4ccabf18728bdcd5b78b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': True, 'log_level': 'INFO', 's…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/TF-horovod/runs/TF-horovod_1573636453_7e86d133?wsid=/subscriptions/70b8f39e-8863-49f7-b6ba-34a80799550c/resourcegroups/azuremlserviceresourcegroup/workspaces/azuremlservice\", \"run_id\": \"TF-horovod_1573636453_7e86d133\", \"run_properties\": {\"run_id\": \"TF-horovod_1573636453_7e86d133\", \"created_utc\": \"2019-11-13T09:14:15.184398Z\", \"properties\": {\"_azureml.ComputeTargetType\": \"batchai\", \"ContentSnapshotId\": \"a61d8890-9078-4e00-913d-4b143e7b2b58\", \"AzureML.DerivedImageName\": \"azureml/azureml_75651667c3311d0b90ca821953173db3\", \"ProcessInfoFile\": \"azureml-logs/process_info.json\", \"ProcessStatusFile\": \"azureml-logs/process_status.json\"}, \"tags\": {\"_aml_system_ComputeTargetStatus\": \"{\\\"AllocationState\\\":\\\"steady\\\",\\\"PreparingNodeCount\\\":2,\\\"RunningNodeCount\\\":0,\\\"CurrentNodeCount\\\":2}\"}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": \"2019-11-13T09:23:39.968915Z\", \"status\": \"Completed\", \"log_files\": {\"azureml-logs/55_azureml-execution-tvmps_54b9e9f6168a3c4e088c3662404c6c4132ba167eae0677282802cbc665083b71_d.txt\": \"https://azuremlservice8628362969.blob.core.windows.net/azureml/ExperimentRun/dcid.TF-horovod_1573636453_7e86d133/azureml-logs/55_azureml-execution-tvmps_54b9e9f6168a3c4e088c3662404c6c4132ba167eae0677282802cbc665083b71_d.txt?sv=2019-02-02&sr=b&sig=kkwQ9XEv2cvRlww2AKLvFi6jc4Gvm9tCCQrC%2B17Avd8%3D&st=2019-11-13T09%3A13%3A54Z&se=2019-11-13T17%3A23%3A54Z&sp=r\", \"azureml-logs/55_azureml-execution-tvmps_d1086d85e0a90940cdf2dc1b0c34d911379cf1de1209059c2533c2a99ca79f08_d.txt\": \"https://azuremlservice8628362969.blob.core.windows.net/azureml/ExperimentRun/dcid.TF-horovod_1573636453_7e86d133/azureml-logs/55_azureml-execution-tvmps_d1086d85e0a90940cdf2dc1b0c34d911379cf1de1209059c2533c2a99ca79f08_d.txt?sv=2019-02-02&sr=b&sig=9CcaXFFOtbcmmHVRvEWbjJeybYOoJlsW97tfxs1uILc%3D&st=2019-11-13T09%3A13%3A54Z&se=2019-11-13T17%3A23%3A54Z&sp=r\", \"azureml-logs/65_job_prep-tvmps_54b9e9f6168a3c4e088c3662404c6c4132ba167eae0677282802cbc665083b71_d.txt\": \"https://azuremlservice8628362969.blob.core.windows.net/azureml/ExperimentRun/dcid.TF-horovod_1573636453_7e86d133/azureml-logs/65_job_prep-tvmps_54b9e9f6168a3c4e088c3662404c6c4132ba167eae0677282802cbc665083b71_d.txt?sv=2019-02-02&sr=b&sig=QitoO%2BERgSFdgg5bUaMRwNwT5PhrwzWKtmW68QcrUKM%3D&st=2019-11-13T09%3A13%3A54Z&se=2019-11-13T17%3A23%3A54Z&sp=r\", \"azureml-logs/65_job_prep-tvmps_d1086d85e0a90940cdf2dc1b0c34d911379cf1de1209059c2533c2a99ca79f08_d.txt\": \"https://azuremlservice8628362969.blob.core.windows.net/azureml/ExperimentRun/dcid.TF-horovod_1573636453_7e86d133/azureml-logs/65_job_prep-tvmps_d1086d85e0a90940cdf2dc1b0c34d911379cf1de1209059c2533c2a99ca79f08_d.txt?sv=2019-02-02&sr=b&sig=RiGNS1apA4YS0OmoBICLy1HEhGl0bWGa5ESLGHSMi6g%3D&st=2019-11-13T09%3A13%3A54Z&se=2019-11-13T17%3A23%3A54Z&sp=r\", \"azureml-logs/70_driver_log_0.txt\": \"https://azuremlservice8628362969.blob.core.windows.net/azureml/ExperimentRun/dcid.TF-horovod_1573636453_7e86d133/azureml-logs/70_driver_log_0.txt?sv=2019-02-02&sr=b&sig=4uQYZFpwUJT%2BREulCFCT5bRf6gmuKhqII5Ep%2FJw4C4o%3D&st=2019-11-13T09%3A13%3A54Z&se=2019-11-13T17%3A23%3A54Z&sp=r\", \"azureml-logs/70_driver_log_1.txt\": \"https://azuremlservice8628362969.blob.core.windows.net/azureml/ExperimentRun/dcid.TF-horovod_1573636453_7e86d133/azureml-logs/70_driver_log_1.txt?sv=2019-02-02&sr=b&sig=uSCMaCY%2FfygTHY2kGoDgVK12iKWEogeJL4jXlHGGxqw%3D&st=2019-11-13T09%3A13%3A54Z&se=2019-11-13T17%3A23%3A54Z&sp=r\", \"azureml-logs/70_mpi_log.txt\": \"https://azuremlservice8628362969.blob.core.windows.net/azureml/ExperimentRun/dcid.TF-horovod_1573636453_7e86d133/azureml-logs/70_mpi_log.txt?sv=2019-02-02&sr=b&sig=s8sS9%2BHfsJLTMK3C6VnReRgIB17A4GMEqsrwbUJEfFo%3D&st=2019-11-13T09%3A13%3A54Z&se=2019-11-13T17%3A23%3A54Z&sp=r\", \"azureml-logs/75_job_post-tvmps_54b9e9f6168a3c4e088c3662404c6c4132ba167eae0677282802cbc665083b71_d.txt\": \"https://azuremlservice8628362969.blob.core.windows.net/azureml/ExperimentRun/dcid.TF-horovod_1573636453_7e86d133/azureml-logs/75_job_post-tvmps_54b9e9f6168a3c4e088c3662404c6c4132ba167eae0677282802cbc665083b71_d.txt?sv=2019-02-02&sr=b&sig=9dCRNknK0zp4Fvp1O0vL3Qn2MZ8YUEfCdS1l6Ue8npM%3D&st=2019-11-13T09%3A13%3A54Z&se=2019-11-13T17%3A23%3A54Z&sp=r\", \"azureml-logs/75_job_post-tvmps_d1086d85e0a90940cdf2dc1b0c34d911379cf1de1209059c2533c2a99ca79f08_d.txt\": \"https://azuremlservice8628362969.blob.core.windows.net/azureml/ExperimentRun/dcid.TF-horovod_1573636453_7e86d133/azureml-logs/75_job_post-tvmps_d1086d85e0a90940cdf2dc1b0c34d911379cf1de1209059c2533c2a99ca79f08_d.txt?sv=2019-02-02&sr=b&sig=M6ozn6WYoHUcw0ZeW9mwmpygOZxrJkUIGQ3TyWGO9PY%3D&st=2019-11-13T09%3A13%3A54Z&se=2019-11-13T17%3A23%3A54Z&sp=r\", \"azureml-logs/process_info.json\": \"https://azuremlservice8628362969.blob.core.windows.net/azureml/ExperimentRun/dcid.TF-horovod_1573636453_7e86d133/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=gLPU%2BeVzzj0eWltTeIA%2F%2FIC71s2iYFOJA3Uu0%2FO%2F180%3D&st=2019-11-13T09%3A13%3A54Z&se=2019-11-13T17%3A23%3A54Z&sp=r\", \"azureml-logs/process_status.json\": \"https://azuremlservice8628362969.blob.core.windows.net/azureml/ExperimentRun/dcid.TF-horovod_1573636453_7e86d133/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=vtn8OGunPuLZwL0pPVwW7E%2BRCh%2BkWxFtxxjfOvIpaZA%3D&st=2019-11-13T09%3A13%3A54Z&se=2019-11-13T17%3A23%3A54Z&sp=r\", \"logs/azureml/0_157_azureml.log\": \"https://azuremlservice8628362969.blob.core.windows.net/azureml/ExperimentRun/dcid.TF-horovod_1573636453_7e86d133/logs/azureml/0_157_azureml.log?sv=2019-02-02&sr=b&sig=N1gxBYH91CTnEAMAHDvuXDrvUAmXjhY8YTgs9iaBZ%2Fg%3D&st=2019-11-13T09%3A13%3A54Z&se=2019-11-13T17%3A23%3A54Z&sp=r\", \"logs/azureml/1_113_azureml.log\": \"https://azuremlservice8628362969.blob.core.windows.net/azureml/ExperimentRun/dcid.TF-horovod_1573636453_7e86d133/logs/azureml/1_113_azureml.log?sv=2019-02-02&sr=b&sig=VffAJe1ST0KylK1dXOVdfWSldLyWbzHlase%2B0Q%2FygYc%3D&st=2019-11-13T09%3A13%3A54Z&se=2019-11-13T17%3A23%3A54Z&sp=r\", \"logs/azureml/azureml.log\": \"https://azuremlservice8628362969.blob.core.windows.net/azureml/ExperimentRun/dcid.TF-horovod_1573636453_7e86d133/logs/azureml/azureml.log?sv=2019-02-02&sr=b&sig=YRmGc861xUeK7c6q8GgecXANuP8jrELBhvg2d2I4elk%3D&st=2019-11-13T09%3A13%3A54Z&se=2019-11-13T17%3A23%3A54Z&sp=r\"}, \"log_groups\": [[\"azureml-logs/process_info.json\", \"azureml-logs/process_status.json\", \"logs/azureml/azureml.log\"], [\"logs/azureml/0_157_azureml.log\"], [\"logs/azureml/1_113_azureml.log\"], [\"azureml-logs/55_azureml-execution-tvmps_54b9e9f6168a3c4e088c3662404c6c4132ba167eae0677282802cbc665083b71_d.txt\", \"azureml-logs/55_azureml-execution-tvmps_d1086d85e0a90940cdf2dc1b0c34d911379cf1de1209059c2533c2a99ca79f08_d.txt\"], [\"azureml-logs/65_job_prep-tvmps_54b9e9f6168a3c4e088c3662404c6c4132ba167eae0677282802cbc665083b71_d.txt\", \"azureml-logs/65_job_prep-tvmps_d1086d85e0a90940cdf2dc1b0c34d911379cf1de1209059c2533c2a99ca79f08_d.txt\"], [\"azureml-logs/70_mpi_log.txt\", \"azureml-logs/70_driver_log_0.txt\", \"azureml-logs/70_driver_log_1.txt\"], [\"azureml-logs/75_job_post-tvmps_54b9e9f6168a3c4e088c3662404c6c4132ba167eae0677282802cbc665083b71_d.txt\", \"azureml-logs/75_job_post-tvmps_d1086d85e0a90940cdf2dc1b0c34d911379cf1de1209059c2533c2a99ca79f08_d.txt\"]], \"run_duration\": \"0:09:24\"}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [{\"name\": \"Loss\", \"run_id\": \"TF-horovod_1573636453_7e86d133\", \"categories\": [0, 1, 2, 3], \"series\": [{\"data\": [282.6009521484375, 296.9656066894531, 87.388257294178, 86.47496097064018]}]}], \"run_logs\": \"bash: /azureml-envs/azureml_87bf8b18f50c3819153ad5fad9efbcd9/lib/libtinfo.so.5: no version information available (required by bash)\\r\\nStarting job release. Current time:2019-11-13T09:23:11.012224\\r\\nLogging experiment finalizing status in history service.\\r\\nStarting the daemon thread to refresh tokens in background for process with pid = 367\\r\\nJob release is complete. Current time:2019-11-13T09:23:14.056162\\r\\n\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": true, \"log_level\": \"INFO\", \"sdk_version\": \"1.0.72\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'runId': 'TF-horovod_1573636453_7e86d133',\n",
       " 'target': 'gpu-cluster',\n",
       " 'status': 'Completed',\n",
       " 'startTimeUtc': '2019-11-13T09:18:26.141652Z',\n",
       " 'endTimeUtc': '2019-11-13T09:23:39.968915Z',\n",
       " 'properties': {'_azureml.ComputeTargetType': 'batchai',\n",
       "  'ContentSnapshotId': 'a61d8890-9078-4e00-913d-4b143e7b2b58',\n",
       "  'AzureML.DerivedImageName': 'azureml/azureml_75651667c3311d0b90ca821953173db3',\n",
       "  'ProcessInfoFile': 'azureml-logs/process_info.json',\n",
       "  'ProcessStatusFile': 'azureml-logs/process_status.json'},\n",
       " 'inputDatasets': [{'dataset': {'id': '113c9925-6a23-467e-8106-8a7c0ce308a4'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'mattmahoney', 'mechanism': 'Mount'}}],\n",
       " 'runDefinition': {'script': 'tf_horovod_word2vec.py',\n",
       "  'arguments': ['--input_data', 'DatasetConsumptionConfig:mattmahoney'],\n",
       "  'sourceDirectoryDataStore': 'workspaceblobstore',\n",
       "  'framework': 'Python',\n",
       "  'communicator': 'Mpi',\n",
       "  'target': 'gpu-cluster',\n",
       "  'dataReferences': {'workspaceblobstore': {'dataStoreName': 'workspaceblobstore',\n",
       "    'mode': 'Mount',\n",
       "    'pathOnDataStore': None,\n",
       "    'pathOnCompute': None,\n",
       "    'overwrite': False}},\n",
       "  'data': {'mattmahoney': {'dataLocation': {'dataset': {'id': '113c9925-6a23-467e-8106-8a7c0ce308a4'},\n",
       "     'dataPath': None},\n",
       "    'createOutputDirectories': False,\n",
       "    'mechanism': 'Mount',\n",
       "    'environmentVariableName': 'mattmahoney',\n",
       "    'pathOnCompute': None,\n",
       "    'overwrite': False}},\n",
       "  'jobName': None,\n",
       "  'maxRunDurationSeconds': None,\n",
       "  'nodeCount': 2,\n",
       "  'environment': {'name': 'Experiment TF-horovod Environment',\n",
       "   'version': 'Autosave_2019-11-13T07:39:51Z_13a6a328',\n",
       "   'python': {'interpreterPath': 'python',\n",
       "    'userManagedDependencies': False,\n",
       "    'condaDependencies': {'channels': ['conda-forge'],\n",
       "     'dependencies': ['python=3.6.2',\n",
       "      {'pip': ['azureml-dataprep[pandas,fuse]',\n",
       "        'azureml-defaults',\n",
       "        'tensorflow-gpu==1.13.1',\n",
       "        'horovod==0.16.1']}],\n",
       "     'name': 'azureml_87bf8b18f50c3819153ad5fad9efbcd9'},\n",
       "    'baseCondaEnvironment': None},\n",
       "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'docker': {'baseImage': 'mcr.microsoft.com/azureml/base-gpu:intelmpi2018.3-cuda10.0-cudnn7-ubuntu16.04',\n",
       "    'baseDockerfile': None,\n",
       "    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n",
       "    'enabled': True,\n",
       "    'arguments': []},\n",
       "   'spark': {'repositories': [], 'packages': [], 'precachePackages': False},\n",
       "   'inferencingStackVersion': None},\n",
       "  'history': {'outputCollection': True,\n",
       "   'directoriesToWatch': ['logs'],\n",
       "   'snapshotProject': True},\n",
       "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'amlCompute': {'name': None,\n",
       "   'vmSize': None,\n",
       "   'retainCluster': False,\n",
       "   'clusterMaxNodeCount': 2},\n",
       "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
       "  'mpi': {'processCountPerNode': 1},\n",
       "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
       "  'containerInstance': {'region': None, 'cpuCores': 2, 'memoryGb': 3.5},\n",
       "  'exposedPorts': None,\n",
       "  'docker': {'useDocker': True,\n",
       "   'sharedVolumes': True,\n",
       "   'shmSize': '2g',\n",
       "   'arguments': []}},\n",
       " 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_54b9e9f6168a3c4e088c3662404c6c4132ba167eae0677282802cbc665083b71_d.txt': 'https://azuremlservice8628362969.blob.core.windows.net/azureml/ExperimentRun/dcid.TF-horovod_1573636453_7e86d133/azureml-logs/55_azureml-execution-tvmps_54b9e9f6168a3c4e088c3662404c6c4132ba167eae0677282802cbc665083b71_d.txt?sv=2019-02-02&sr=b&sig=3LTv7btOrsFDrCYPOr5EQ0MdLl8TkVWwZEFzHHX%2FyyI%3D&st=2019-11-13T09%3A14%3A55Z&se=2019-11-13T17%3A24%3A55Z&sp=r',\n",
       "  'azureml-logs/55_azureml-execution-tvmps_d1086d85e0a90940cdf2dc1b0c34d911379cf1de1209059c2533c2a99ca79f08_d.txt': 'https://azuremlservice8628362969.blob.core.windows.net/azureml/ExperimentRun/dcid.TF-horovod_1573636453_7e86d133/azureml-logs/55_azureml-execution-tvmps_d1086d85e0a90940cdf2dc1b0c34d911379cf1de1209059c2533c2a99ca79f08_d.txt?sv=2019-02-02&sr=b&sig=38yhB5tD8WRr1V7xPCyQY6WG7oCgTeGI%2BbADoI0MiKQ%3D&st=2019-11-13T09%3A14%3A55Z&se=2019-11-13T17%3A24%3A55Z&sp=r',\n",
       "  'azureml-logs/65_job_prep-tvmps_54b9e9f6168a3c4e088c3662404c6c4132ba167eae0677282802cbc665083b71_d.txt': 'https://azuremlservice8628362969.blob.core.windows.net/azureml/ExperimentRun/dcid.TF-horovod_1573636453_7e86d133/azureml-logs/65_job_prep-tvmps_54b9e9f6168a3c4e088c3662404c6c4132ba167eae0677282802cbc665083b71_d.txt?sv=2019-02-02&sr=b&sig=PFVPaC%2BxOJbngasi5GR23EQbh6nNDlTmwW5jyyPOFYg%3D&st=2019-11-13T09%3A14%3A55Z&se=2019-11-13T17%3A24%3A55Z&sp=r',\n",
       "  'azureml-logs/65_job_prep-tvmps_d1086d85e0a90940cdf2dc1b0c34d911379cf1de1209059c2533c2a99ca79f08_d.txt': 'https://azuremlservice8628362969.blob.core.windows.net/azureml/ExperimentRun/dcid.TF-horovod_1573636453_7e86d133/azureml-logs/65_job_prep-tvmps_d1086d85e0a90940cdf2dc1b0c34d911379cf1de1209059c2533c2a99ca79f08_d.txt?sv=2019-02-02&sr=b&sig=bNGjVeON6Pes3jQB141JcDUup1QtfprW2FVY9uMcCKQ%3D&st=2019-11-13T09%3A14%3A55Z&se=2019-11-13T17%3A24%3A55Z&sp=r',\n",
       "  'azureml-logs/70_driver_log_0.txt': 'https://azuremlservice8628362969.blob.core.windows.net/azureml/ExperimentRun/dcid.TF-horovod_1573636453_7e86d133/azureml-logs/70_driver_log_0.txt?sv=2019-02-02&sr=b&sig=uYM26jcZzifqPyB0SsrZMBUVIU%2BC2EFpuAoZJTUpcMs%3D&st=2019-11-13T09%3A14%3A55Z&se=2019-11-13T17%3A24%3A55Z&sp=r',\n",
       "  'azureml-logs/70_driver_log_1.txt': 'https://azuremlservice8628362969.blob.core.windows.net/azureml/ExperimentRun/dcid.TF-horovod_1573636453_7e86d133/azureml-logs/70_driver_log_1.txt?sv=2019-02-02&sr=b&sig=95LyU1Alltl2zEcTcK7v1%2FpVbIRwlYxBNhWl6lUhWc8%3D&st=2019-11-13T09%3A14%3A55Z&se=2019-11-13T17%3A24%3A55Z&sp=r',\n",
       "  'azureml-logs/70_mpi_log.txt': 'https://azuremlservice8628362969.blob.core.windows.net/azureml/ExperimentRun/dcid.TF-horovod_1573636453_7e86d133/azureml-logs/70_mpi_log.txt?sv=2019-02-02&sr=b&sig=dAh3uI%2FXw3I5DjSXa7QL3rBEUQH97ND6COQkgqUEhXs%3D&st=2019-11-13T09%3A14%3A55Z&se=2019-11-13T17%3A24%3A55Z&sp=r',\n",
       "  'azureml-logs/75_job_post-tvmps_54b9e9f6168a3c4e088c3662404c6c4132ba167eae0677282802cbc665083b71_d.txt': 'https://azuremlservice8628362969.blob.core.windows.net/azureml/ExperimentRun/dcid.TF-horovod_1573636453_7e86d133/azureml-logs/75_job_post-tvmps_54b9e9f6168a3c4e088c3662404c6c4132ba167eae0677282802cbc665083b71_d.txt?sv=2019-02-02&sr=b&sig=zpuU4DIGOXyJVnGqWZgNhl%2FIBtKH3%2FRnc5mK6nQEplM%3D&st=2019-11-13T09%3A14%3A55Z&se=2019-11-13T17%3A24%3A55Z&sp=r',\n",
       "  'azureml-logs/75_job_post-tvmps_d1086d85e0a90940cdf2dc1b0c34d911379cf1de1209059c2533c2a99ca79f08_d.txt': 'https://azuremlservice8628362969.blob.core.windows.net/azureml/ExperimentRun/dcid.TF-horovod_1573636453_7e86d133/azureml-logs/75_job_post-tvmps_d1086d85e0a90940cdf2dc1b0c34d911379cf1de1209059c2533c2a99ca79f08_d.txt?sv=2019-02-02&sr=b&sig=rP2uAHLuL0AsMenB0QENOMqMoKpcL%2FDRWtagbSN3pbs%3D&st=2019-11-13T09%3A14%3A55Z&se=2019-11-13T17%3A24%3A55Z&sp=r',\n",
       "  'azureml-logs/process_info.json': 'https://azuremlservice8628362969.blob.core.windows.net/azureml/ExperimentRun/dcid.TF-horovod_1573636453_7e86d133/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=UTrR38g0IzJOn3Ycl3LFDmdp9LiIP8VMegofZeJBAnU%3D&st=2019-11-13T09%3A14%3A55Z&se=2019-11-13T17%3A24%3A55Z&sp=r',\n",
       "  'azureml-logs/process_status.json': 'https://azuremlservice8628362969.blob.core.windows.net/azureml/ExperimentRun/dcid.TF-horovod_1573636453_7e86d133/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=PgyKmfc2JHJK1HV%2BbCuxYEfqRLyvm12netXdtw8AUjE%3D&st=2019-11-13T09%3A14%3A55Z&se=2019-11-13T17%3A24%3A55Z&sp=r',\n",
       "  'logs/azureml/0_157_azureml.log': 'https://azuremlservice8628362969.blob.core.windows.net/azureml/ExperimentRun/dcid.TF-horovod_1573636453_7e86d133/logs/azureml/0_157_azureml.log?sv=2019-02-02&sr=b&sig=nUl%2B0QAOsIMWaAexnOrRtCfc%2BAHJMjKxXwAK%2BHHMXYY%3D&st=2019-11-13T09%3A14%3A55Z&se=2019-11-13T17%3A24%3A55Z&sp=r',\n",
       "  'logs/azureml/1_113_azureml.log': 'https://azuremlservice8628362969.blob.core.windows.net/azureml/ExperimentRun/dcid.TF-horovod_1573636453_7e86d133/logs/azureml/1_113_azureml.log?sv=2019-02-02&sr=b&sig=SEAkFrMjt4cNRbSBMt64Gn5zlWbRb9E8zvXlsKOHGOo%3D&st=2019-11-13T09%3A14%3A55Z&se=2019-11-13T17%3A24%3A55Z&sp=r',\n",
       "  'logs/azureml/azureml.log': 'https://azuremlservice8628362969.blob.core.windows.net/azureml/ExperimentRun/dcid.TF-horovod_1573636453_7e86d133/logs/azureml/azureml.log?sv=2019-02-02&sr=b&sig=%2BW%2FDaC4AD6sksi43exIY1vXtfne5l07b1Rl3OoGnaSY%3D&st=2019-11-13T09%3A14%3A55Z&se=2019-11-13T17%3A24%3A55Z&sp=r'}}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.get_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "maxluk"
   }
  ],
  "category": "training",
  "compute": [
   "AML Compute"
  ],
  "datasets": [
   "None"
  ],
  "deployment": [
   "None"
  ],
  "exclude_from_index": false,
  "framework": [
   "TensorFlow"
  ],
  "friendly_name": "Distributed training using TensorFlow with Horovod",
  "index_order": 1,
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "tags": [
   "None"
  ],
  "task": "Use the TensorFlow estimator to train a word2vec model"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
