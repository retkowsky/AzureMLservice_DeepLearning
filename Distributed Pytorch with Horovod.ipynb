{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed PyTorch with Horovod\n",
    "In this tutorial, you will train a PyTorch model on the [MNIST](http://yann.lecun.com/exdb/mnist/) dataset using distributed training via [Horovod](https://github.com/uber/horovod) across a GPU cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "* If you are using an Azure Machine Learning Notebook VM, you are all set. Otherwise, go through the [Configuration](../../../configuration.ipynb) notebook to install the Azure Machine Learning Python SDK and create an Azure ML `Workspace`\n",
    "* Review the [tutorial](../train-hyperparameter-tune-deploy-with-pytorch/train-hyperparameter-tune-deploy-with-pytorch.ipynb) on single-node PyTorch training using Azure Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK version: 1.0.72\n"
     ]
    }
   ],
   "source": [
    "# Check core SDK version number\n",
    "import azureml.core\n",
    "\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize workspace\n",
    "\n",
    "Initialize a [Workspace](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#workspace) object from the existing workspace you created in the Prerequisites step. `Workspace.from_config()` creates a workspace object from the details stored in `config.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workspace name: azuremlservice\n",
      "Azure region: westeurope\n",
      "Subscription id: 70b8f39e-8863-49f7-b6ba-34a80799550c\n",
      "Resource group: azuremlserviceresourcegroup\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.workspace import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create or attach existing AmlCompute\n",
    "You will need to create a [compute target](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#compute-target) for training your model. In this tutorial, we use Azure ML managed compute ([AmlCompute](https://docs.microsoft.com/azure/machine-learning/service/how-to-set-up-training-targets#amlcompute)) for our remote training compute resource. Specifically, the below code creates an `STANDARD_NC6` GPU cluster that autoscales from `0` to `4` nodes.\n",
    "\n",
    "**Creation of AmlCompute takes approximately 5 minutes.** If the AmlCompute with that name is already in your workspace, this code will skip the creation process.\n",
    "\n",
    "As with other Azure services, there are limits on certain resources (e.g. AmlCompute) associated with the Azure Machine Learning service. Please read [this article](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-manage-quotas) on the default limits and how to request more quota."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing compute target.\n",
      "{'currentNodeCount': 2, 'targetNodeCount': 2, 'nodeStateCounts': {'preparingNodeCount': 2, 'runningNodeCount': 0, 'idleNodeCount': 0, 'unusableNodeCount': 0, 'leavingNodeCount': 0, 'preemptedNodeCount': 0}, 'allocationState': 'Steady', 'allocationStateTransitionTime': '2019-11-13T08:39:34.644000+00:00', 'errors': None, 'creationTime': '2019-11-13T08:36:36.805276+00:00', 'modifiedTime': '2019-11-13T08:36:52.296147+00:00', 'provisioningState': 'Succeeded', 'provisioningStateTransitionTime': None, 'scaleSettings': {'minNodeCount': 0, 'maxNodeCount': 4, 'nodeIdleTimeBeforeScaleDown': 'PT120S'}, 'vmPriority': 'Dedicated', 'vmSize': 'STANDARD_NC6'}\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# choose a name for your cluster\n",
    "cluster_name = \"gpu-cluster3\"\n",
    "\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing compute target.')\n",
    "except ComputeTargetException:\n",
    "    print('Creating a new compute target...')\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_NC6',\n",
    "                                                           max_nodes=4)\n",
    "\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "\n",
    "    compute_target.wait_for_completion(show_output=True)\n",
    "\n",
    "# use get_status() to get a detailed status for the current AmlCompute. \n",
    "print(compute_target.get_status().serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code creates GPU compute. If you instead want to create CPU compute, provide a different VM size to the `vm_size` parameter, such as `STANDARD_D2_V2`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model on the remote compute\n",
    "Now that we have the AmlCompute ready to go, let's run our distributed training job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a project directory\n",
    "Create a directory that will contain all the necessary code from your local machine that you will need access to on the remote resource. This includes the training script and any additional files your training script depends on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "project_folder = './pytorch-distr-hvd'\n",
    "os.makedirs(project_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare training script\n",
    "Now you will need to create your training script. In this tutorial, the script for distributed training of MNIST is already provided for you at `pytorch_horovod_mnist.py`. In practice, you should be able to take any custom PyTorch training script as is and run it with Azure ML without having to modify your code.\n",
    "\n",
    "However, if you would like to use Azure ML's [metric logging](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#logging) capabilities, you will have to add a small amount of Azure ML logic inside your training script. In this example, at each logging interval, we will log the loss for that minibatch to our Azure ML run.\n",
    "\n",
    "To do so, in `pytorch_horovod_mnist.py`, we will first access the Azure ML `Run` object within the script:\n",
    "```Python\n",
    "from azureml.core.run import Run\n",
    "run = Run.get_context()\n",
    "```\n",
    "Later within the script, we log the loss metric to our run:\n",
    "```Python\n",
    "run.log('loss', loss.item())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once your script is ready, copy the training script `pytorch_horovod_mnist.py` into the project directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./pytorch-distr-hvd/pytorch_horovod_mnist.py'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "shutil.copy('pytorch_horovod_mnist.py', project_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an experiment\n",
    "Create an [Experiment](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#experiment) to track all the runs in your workspace for this distributed PyTorch tutorial. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "\n",
    "experiment_name = 'pytorch-horovod'\n",
    "experiment = Experiment(ws, name=experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a PyTorch estimator\n",
    "The Azure ML SDK's PyTorch estimator enables you to easily submit PyTorch training jobs for both single-node and distributed runs. For more information on the PyTorch estimator, refer [here](https://docs.microsoft.com/azure/machine-learning/service/how-to-train-pytorch)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - framework_version is not specified, defaulting to version 1.3.\n"
     ]
    }
   ],
   "source": [
    "from azureml.train.dnn import PyTorch, Mpi\n",
    "\n",
    "estimator = PyTorch(source_directory=project_folder,\n",
    "                    compute_target=compute_target,\n",
    "                    entry_script='pytorch_horovod_mnist.py',\n",
    "                    node_count=2,\n",
    "                    distributed_training=Mpi(),\n",
    "                    use_gpu=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code specifies that we will run our training script on `2` nodes, with one worker per node. In order to execute a distributed run using MPI/Horovod, you must provide the argument `distributed_backend=Mpi()`. To specify `i` workers per node, you must provide the argument `distributed_backend=Mpi(process_count_per_node=i)`. Using this estimator with these settings, PyTorch, Horovod and their dependencies will be installed for you. However, if your script also uses other packages, make sure to install them via the `PyTorch` constructor's `pip_packages` or `conda_packages` parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit job\n",
    "Run your experiment by submitting your estimator object. Note that this call is asynchronous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run(Experiment: pytorch-horovod,\n",
      "Id: pytorch-horovod_1573634404_8afb0430,\n",
      "Type: azureml.scriptrun,\n",
      "Status: Starting)\n"
     ]
    }
   ],
   "source": [
    "run = experiment.submit(estimator)\n",
    "print(run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitor your run\n",
    "You can monitor the progress of the run with a Jupyter widget. Like the run submission, the widget is asynchronous and provides live updates every 10-15 seconds until the job completes. You can see that the widget automatically plots and visualizes the loss metric that we logged to the Azure ML run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f73a13f0855430ca9aca5b70eaf0e94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': True, 'log_level': 'INFO', 's…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/pytorch-horovod/runs/pytorch-horovod_1573634404_8afb0430?wsid=/subscriptions/70b8f39e-8863-49f7-b6ba-34a80799550c/resourcegroups/azuremlserviceresourcegroup/workspaces/azuremlservice\", \"run_id\": \"pytorch-horovod_1573634404_8afb0430\", \"run_properties\": {\"run_id\": \"pytorch-horovod_1573634404_8afb0430\", \"created_utc\": \"2019-11-13T08:40:05.253178Z\", \"properties\": {\"_azureml.ComputeTargetType\": \"batchai\", \"ContentSnapshotId\": \"bcddcc94-ef59-4acd-a2ae-25bad4327c3b\", \"ProcessInfoFile\": \"azureml-logs/process_info.json\", \"ProcessStatusFile\": \"azureml-logs/process_status.json\"}, \"tags\": {\"_aml_system_ComputeTargetStatus\": \"{\\\"AllocationState\\\":\\\"resizing\\\",\\\"PreparingNodeCount\\\":0,\\\"RunningNodeCount\\\":0,\\\"CurrentNodeCount\\\":2}\"}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": \"2019-11-13T08:47:14.071317Z\", \"status\": \"Completed\", \"log_files\": {\"azureml-logs/55_azureml-execution-tvmps_4620380688f8b9a2b15fc6c79b5173705dcc525a0bcddaeb524564996082c187_d.txt\": \"https://azuremlservice8628362969.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-horovod_1573634404_8afb0430/azureml-logs/55_azureml-execution-tvmps_4620380688f8b9a2b15fc6c79b5173705dcc525a0bcddaeb524564996082c187_d.txt?sv=2019-02-02&sr=b&sig=srBH8o96ITcIjfUt5%2BQOXaf5j%2BIlG077wBsaydlc96E%3D&st=2019-11-13T08%3A37%3A25Z&se=2019-11-13T16%3A47%3A25Z&sp=r\", \"azureml-logs/55_azureml-execution-tvmps_f94f9ecdee1404f1f927943252320b16c287bedf1d179c39837c286721cf0ef8_d.txt\": \"https://azuremlservice8628362969.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-horovod_1573634404_8afb0430/azureml-logs/55_azureml-execution-tvmps_f94f9ecdee1404f1f927943252320b16c287bedf1d179c39837c286721cf0ef8_d.txt?sv=2019-02-02&sr=b&sig=1lW6nhjx0kCJjBVBzG808alM%2Bdu3plBlmXJkJudnfgk%3D&st=2019-11-13T08%3A37%3A25Z&se=2019-11-13T16%3A47%3A25Z&sp=r\", \"azureml-logs/65_job_prep-tvmps_4620380688f8b9a2b15fc6c79b5173705dcc525a0bcddaeb524564996082c187_d.txt\": \"https://azuremlservice8628362969.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-horovod_1573634404_8afb0430/azureml-logs/65_job_prep-tvmps_4620380688f8b9a2b15fc6c79b5173705dcc525a0bcddaeb524564996082c187_d.txt?sv=2019-02-02&sr=b&sig=aF1sX%2BJf34NSoKCj0Z555ln%2FFaRezccz10iVek5teVY%3D&st=2019-11-13T08%3A37%3A25Z&se=2019-11-13T16%3A47%3A25Z&sp=r\", \"azureml-logs/65_job_prep-tvmps_f94f9ecdee1404f1f927943252320b16c287bedf1d179c39837c286721cf0ef8_d.txt\": \"https://azuremlservice8628362969.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-horovod_1573634404_8afb0430/azureml-logs/65_job_prep-tvmps_f94f9ecdee1404f1f927943252320b16c287bedf1d179c39837c286721cf0ef8_d.txt?sv=2019-02-02&sr=b&sig=U0YoYkQGHkZ4ja2tIe6iGyViEtlYUnt%2F8Nn5AhgQiSw%3D&st=2019-11-13T08%3A37%3A25Z&se=2019-11-13T16%3A47%3A25Z&sp=r\", \"azureml-logs/70_driver_log_0.txt\": \"https://azuremlservice8628362969.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-horovod_1573634404_8afb0430/azureml-logs/70_driver_log_0.txt?sv=2019-02-02&sr=b&sig=4ReKVGDrIrE8qN4h4%2FlcYvqUfzDZ3uc%2FVDQXS%2FDCyi4%3D&st=2019-11-13T08%3A37%3A25Z&se=2019-11-13T16%3A47%3A25Z&sp=r\", \"azureml-logs/70_driver_log_1.txt\": \"https://azuremlservice8628362969.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-horovod_1573634404_8afb0430/azureml-logs/70_driver_log_1.txt?sv=2019-02-02&sr=b&sig=0RmAB5S7Q5m6HfR1%2BmP%2BXXFYO%2BCMhhYAeExRYCKgEGU%3D&st=2019-11-13T08%3A37%3A25Z&se=2019-11-13T16%3A47%3A25Z&sp=r\", \"azureml-logs/70_mpi_log.txt\": \"https://azuremlservice8628362969.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-horovod_1573634404_8afb0430/azureml-logs/70_mpi_log.txt?sv=2019-02-02&sr=b&sig=Q622wS279hXh38rXGsAgNUNgcX1Ba6A80CINeiCSsrc%3D&st=2019-11-13T08%3A37%3A25Z&se=2019-11-13T16%3A47%3A25Z&sp=r\", \"azureml-logs/75_job_post-tvmps_4620380688f8b9a2b15fc6c79b5173705dcc525a0bcddaeb524564996082c187_d.txt\": \"https://azuremlservice8628362969.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-horovod_1573634404_8afb0430/azureml-logs/75_job_post-tvmps_4620380688f8b9a2b15fc6c79b5173705dcc525a0bcddaeb524564996082c187_d.txt?sv=2019-02-02&sr=b&sig=m6bE6q8ezyQFoTYSdGcclpLO7Nt6GHnUkz1tfjS8vKM%3D&st=2019-11-13T08%3A37%3A25Z&se=2019-11-13T16%3A47%3A25Z&sp=r\", \"azureml-logs/75_job_post-tvmps_f94f9ecdee1404f1f927943252320b16c287bedf1d179c39837c286721cf0ef8_d.txt\": \"https://azuremlservice8628362969.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-horovod_1573634404_8afb0430/azureml-logs/75_job_post-tvmps_f94f9ecdee1404f1f927943252320b16c287bedf1d179c39837c286721cf0ef8_d.txt?sv=2019-02-02&sr=b&sig=Nn5U%2FuTCqPJMfPDe8JWx50EW10%2F4Nj7cSwMVjPV2Q00%3D&st=2019-11-13T08%3A37%3A25Z&se=2019-11-13T16%3A47%3A25Z&sp=r\", \"azureml-logs/process_info.json\": \"https://azuremlservice8628362969.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-horovod_1573634404_8afb0430/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=UQQobdREM2w7V7is2en1ZKFLq3YfvRUegGjEg%2FQQ1nE%3D&st=2019-11-13T08%3A37%3A25Z&se=2019-11-13T16%3A47%3A25Z&sp=r\", \"azureml-logs/process_status.json\": \"https://azuremlservice8628362969.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-horovod_1573634404_8afb0430/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=zQn6PC98%2Fe1ybi3KYd2ahmNOtI4bkZuWUUuhPNFeVyQ%3D&st=2019-11-13T08%3A37%3A25Z&se=2019-11-13T16%3A47%3A25Z&sp=r\", \"logs/azureml/0_138_azureml.log\": \"https://azuremlservice8628362969.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-horovod_1573634404_8afb0430/logs/azureml/0_138_azureml.log?sv=2019-02-02&sr=b&sig=jWGOHeuYTaDywDQFPK2y50GxkuEXrkcfD1Lsnt654%2F0%3D&st=2019-11-13T08%3A37%3A25Z&se=2019-11-13T16%3A47%3A25Z&sp=r\", \"logs/azureml/1_118_azureml.log\": \"https://azuremlservice8628362969.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-horovod_1573634404_8afb0430/logs/azureml/1_118_azureml.log?sv=2019-02-02&sr=b&sig=XhmUdkGC%2B3aZTSy8rEeoblGqvQCAQOH8jxBrlI5l3A4%3D&st=2019-11-13T08%3A37%3A25Z&se=2019-11-13T16%3A47%3A25Z&sp=r\", \"logs/azureml/azureml.log\": \"https://azuremlservice8628362969.blob.core.windows.net/azureml/ExperimentRun/dcid.pytorch-horovod_1573634404_8afb0430/logs/azureml/azureml.log?sv=2019-02-02&sr=b&sig=f0%2BXtb3wiRU%2F8w6JPmUsgc7pm0mgnflZexOJ5KIAGCI%3D&st=2019-11-13T08%3A37%3A25Z&se=2019-11-13T16%3A47%3A25Z&sp=r\"}, \"log_groups\": [[\"azureml-logs/process_info.json\", \"azureml-logs/process_status.json\", \"logs/azureml/azureml.log\"], [\"logs/azureml/0_138_azureml.log\"], [\"logs/azureml/1_118_azureml.log\"], [\"azureml-logs/55_azureml-execution-tvmps_f94f9ecdee1404f1f927943252320b16c287bedf1d179c39837c286721cf0ef8_d.txt\", \"azureml-logs/55_azureml-execution-tvmps_4620380688f8b9a2b15fc6c79b5173705dcc525a0bcddaeb524564996082c187_d.txt\"], [\"azureml-logs/65_job_prep-tvmps_f94f9ecdee1404f1f927943252320b16c287bedf1d179c39837c286721cf0ef8_d.txt\", \"azureml-logs/65_job_prep-tvmps_4620380688f8b9a2b15fc6c79b5173705dcc525a0bcddaeb524564996082c187_d.txt\"], [\"azureml-logs/70_mpi_log.txt\", \"azureml-logs/70_driver_log_0.txt\", \"azureml-logs/70_driver_log_1.txt\"], [\"azureml-logs/75_job_post-tvmps_f94f9ecdee1404f1f927943252320b16c287bedf1d179c39837c286721cf0ef8_d.txt\", \"azureml-logs/75_job_post-tvmps_4620380688f8b9a2b15fc6c79b5173705dcc525a0bcddaeb524564996082c187_d.txt\"]], \"run_duration\": \"0:07:08\"}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [{\"name\": \"loss\", \"run_id\": \"pytorch-horovod_1573634404_8afb0430\", \"categories\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939], \"series\": [{\"data\": [2.3167672157287598, 2.31312894821167, 2.276857852935791, 2.2646961212158203, 2.2675528526306152, 2.3089582920074463, 2.2974541187286377, 2.2995693683624268, 2.301556348800659, 2.2432138919830322, 2.203784465789795, 2.132638931274414, 2.194941997528076, 1.9862111806869507, 1.7239407300949097, 2.22711181640625, 2.2300562858581543, 2.0769476890563965, 1.9777235984802246, 1.897271990776062, 1.4612106084823608, 1.2434985637664795, 1.2265242338180542, 1.1102100610733032, 1.1113166809082031, 1.7470781803131104, 1.3723772764205933, 1.2702252864837646, 1.0594419240951538, 1.0341787338256836, 1.180239200592041, 0.9618179798126221, 0.8425300717353821, 0.7911648154258728, 0.9416171908378601, 0.8581037521362305, 0.8413951992988586, 1.0428272485733032, 0.8138703107833862, 0.886717677116394, 0.6686486601829529, 0.6906945705413818, 0.6831885576248169, 0.7484525442123413, 0.9443105459213257, 0.7622486352920532, 0.7381199598312378, 0.64687180519104, 0.7134038805961609, 0.6790348291397095, 0.656828761100769, 0.6327275633811951, 0.6468051671981812, 0.7346593141555786, 0.7720776796340942, 0.8712753057479858, 0.40854769945144653, 0.49282389879226685, 0.7963215708732605, 0.5522515773773193, 0.5687761306762695, 0.8880954384803772, 0.755652666091919, 0.41779014468193054, 0.3427322506904602, 0.6457775831222534, 0.5758562088012695, 0.6986830234527588, 0.5413415431976318, 0.4233853816986084, 0.5001057386398315, 0.3798937201499939, 0.3863593339920044, 0.6826056838035583, 0.49748891592025757, 0.596738338470459, 0.31963178515434265, 0.42036300897598267, 0.5883380770683289, 0.49771031737327576, 0.7805685997009277, 0.4108598828315735, 0.5039642453193665, 0.635619580745697, 0.6623902320861816, 0.3760598599910736, 0.39705854654312134, 0.42370426654815674, 0.40754565596580505, 0.5394003987312317, 0.338041216135025, 0.582042932510376, 0.6182214617729187, 0.6278321743011475, 0.5427868366241455, 0.514664351940155, 0.6451447606086731, 0.45831963419914246, 0.6202273964881897, 0.3361620008945465, 0.7874152064323425, 0.5786914825439453, 0.5323911905288696, 0.45824894309043884, 0.5807358026504517, 0.3981923758983612, 0.39739200472831726, 0.445306658744812, 0.30066174268722534, 0.38692212104797363, 0.474540114402771, 0.36495620012283325, 0.5003638863563538, 0.6294687390327454, 0.5107229948043823, 0.38900721073150635, 0.5054159760475159, 0.5817826986312866, 0.467221200466156, 0.487892746925354, 0.5638953447341919, 0.5519387722015381, 0.48708829283714294, 0.5705875158309937, 0.49464115500450134, 0.4831935167312622, 0.30545058846473694, 0.4900277554988861, 0.6180295944213867, 0.7283494472503662, 0.6806220412254333, 0.3839915990829468, 0.42490631341934204, 0.7500057220458984, 0.504406213760376, 0.25570735335350037, 0.5907261371612549, 0.31138747930526733, 0.30315250158309937, 0.48459315299987793, 0.36429136991500854, 0.38583195209503174, 0.35198262333869934, 0.3074636459350586, 0.37657713890075684, 0.4026187062263489, 0.3693736493587494, 0.41304636001586914, 0.5543555021286011, 0.4176315367221832, 0.31480133533477783, 0.21225087344646454, 0.3904140889644623, 0.16429245471954346, 0.39232754707336426, 0.5136960744857788, 0.37746500968933105, 0.20579607784748077, 0.2945477068424225, 0.29275190830230713, 0.39727574586868286, 0.38529619574546814, 0.2671527862548828, 0.3177908658981323, 0.33003368973731995, 0.47615402936935425, 0.3483678996562958, 0.31445518136024475, 0.6568297147750854, 0.33153486251831055, 0.31448549032211304, 0.379374235868454, 0.34066295623779297, 0.4177702069282532, 0.41943150758743286, 0.3110111355781555, 0.3947329819202423, 0.3659210801124573, 0.4758928716182709, 0.4130907654762268, 0.3800617456436157, 0.2275252342224121, 0.3811629116535187, 0.451438844203949, 0.28908655047416687, 0.2921448349952698, 0.2625048756599426, 0.25198403000831604, 0.3416491448879242, 0.3698083162307739, 0.29763150215148926, 0.17283880710601807, 0.44321784377098083, 0.4878147840499878, 0.20901769399642944, 0.23065558075904846, 0.2580588161945343, 0.39205119013786316, 0.2937978506088257, 0.28707218170166016, 0.18554547429084778, 0.30809301137924194, 0.38073235750198364, 0.3956725597381592, 0.4790700078010559, 0.34669092297554016, 0.15371015667915344, 0.4696987271308899, 0.37561115622520447, 0.21152769029140472, 0.31103405356407166, 0.3086862564086914, 0.24065133929252625, 0.39166146516799927, 0.20541855692863464, 0.2974587678909302, 0.4089074730873108, 0.49142345786094666, 0.28859907388687134, 0.17407134175300598, 0.2341739982366562, 0.18762518465518951, 0.4042479395866394, 0.3566354513168335, 0.23689520359039307, 0.22378303110599518, 0.2798857092857361, 0.20348626375198364, 0.2768062949180603, 0.26307153701782227, 0.2966707944869995, 0.6137754917144775, 0.20091001689434052, 0.2558572590351105, 0.23624734580516815, 0.1772908866405487, 0.342192679643631, 0.2243402600288391, 0.21578887104988098, 0.55250084400177, 0.21169742941856384, 0.4807664752006531, 0.35684025287628174, 0.26573216915130615, 0.20053015649318695, 0.28752970695495605, 0.17130936682224274, 0.14903908967971802, 0.23539885878562927, 0.4185168445110321, 0.27788472175598145, 0.29076889157295227, 0.3347465991973877, 0.3728615641593933, 0.35914018750190735, 0.6006205677986145, 0.27328023314476013, 0.30433812737464905, 0.21894074976444244, 0.24602767825126648, 0.1196003407239914, 0.3516673445701599, 0.3658773899078369, 0.2555685043334961, 0.28851839900016785, 0.4015607535839081, 0.15549814701080322, 0.22191216051578522, 0.3756600618362427, 0.31727415323257446, 0.18913166224956512, 0.31091344356536865, 0.33004555106163025, 0.2997305989265442, 0.13499122858047485, 0.32911255955696106, 0.38519471883773804, 0.28322499990463257, 0.3019324839115143, 0.20942391455173492, 0.3424539268016815, 0.39396488666534424, 0.3390210270881653, 0.24983219802379608, 0.2599255442619324, 0.3153940737247467, 0.23902808129787445, 0.2539253830909729, 0.3710836172103882, 0.24662679433822632, 0.3485559821128845, 0.17940545082092285, 0.18203851580619812, 0.2707774341106415, 0.3668064475059509, 0.508779764175415, 0.22427445650100708, 0.29735884070396423, 0.30321788787841797, 0.2961224913597107, 0.24475230276584625, 0.3904033303260803, 0.31641408801078796, 0.33599281311035156, 0.26341405510902405, 0.2633019685745239, 0.2473125010728836, 0.15524619817733765, 0.22011370956897736, 0.11960507184267044, 0.3217077851295471, 0.28890734910964966, 0.23900529742240906, 0.21273423731327057, 0.2102869153022766, 0.5157476663589478, 0.2560950219631195, 0.23196633160114288, 0.44973069429397583, 0.21884532272815704, 0.2885907292366028, 0.4103948473930359, 0.263671875, 0.36965274810791016, 0.3049766421318054, 0.2445584237575531, 0.42047518491744995, 0.2497059404850006, 0.27168160676956177, 0.25876858830451965, 0.26639819145202637, 0.2766229808330536, 0.20693835616111755, 0.2023480236530304, 0.2941707372665405, 0.33803635835647583, 0.30970528721809387, 0.3448505103588104, 0.22391971945762634, 0.2130928933620453, 0.16578711569309235, 0.20903033018112183, 0.2706419825553894, 0.1995614916086197, 0.196160227060318, 0.27680128812789917, 0.22454068064689636, 0.13015273213386536, 0.19685833156108856, 0.1760522723197937, 0.39522451162338257, 0.27219390869140625, 0.39937713742256165, 0.24608351290225983, 0.26318785548210144, 0.3146592974662781, 0.40112316608428955, 0.12139381468296051, 0.28822118043899536, 0.3541041612625122, 0.21697209775447845, 0.2657448947429657, 0.1966148316860199, 0.24668419361114502, 0.3730407655239105, 0.4013417661190033, 0.2322164624929428, 0.32375383377075195, 0.20993481576442719, 0.20365643501281738, 0.5190039873123169, 0.2771507799625397, 0.32862019538879395, 0.3858555555343628, 0.3111756443977356, 0.08367946743965149, 0.22497214376926422, 0.23891562223434448, 0.25369226932525635, 0.30569618940353394, 0.2630559206008911, 0.27993983030319214, 0.32821738719940186, 0.41596898436546326, 0.3048369288444519, 0.24328625202178955, 0.3233940005302429, 0.3931323289871216, 0.4257296323776245, 0.13243290781974792, 0.2657354176044464, 0.40892934799194336, 0.3554093837738037, 0.1881469488143921, 0.24739250540733337, 0.23485197126865387, 0.3381164073944092, 0.3452998101711273, 0.4860691726207733, 0.376231849193573, 0.45499640703201294, 0.32526856660842896, 0.20008742809295654, 0.4507753849029541, 0.14525476098060608, 0.2638907730579376, 0.12465263903141022, 0.19471406936645508, 0.2475542277097702, 0.23622925579547882, 0.3865053057670593, 0.17565710842609406, 0.12445110082626343, 0.20337799191474915, 0.1187962144613266, 0.09706280380487442, 0.3141109347343445, 0.20998866856098175, 0.21120470762252808, 0.26183855533599854, 0.17202550172805786, 0.1961192786693573, 0.34658390283584595, 0.16851337254047394, 0.11173562705516815, 0.32891714572906494, 0.41262340545654297, 0.16283729672431946, 0.3873123526573181, 0.4985229969024658, 0.25182634592056274, 0.362853467464447, 0.22192025184631348, 0.459919810295105, 0.3539382815361023, 0.38829782605171204, 0.20814700424671173, 0.18152180314064026, 0.3836488127708435, 0.28503841161727905, 0.08879567682743073, 0.12034440785646439, 0.27076447010040283, 0.31798598170280457, 0.13628721237182617, 0.3082759976387024, 0.17611806094646454, 0.15736885368824005, 0.06926846504211426, 0.27190327644348145, 0.19871750473976135, 0.2547811269760132, 0.2082281857728958, 0.20295554399490356, 0.169691264629364, 0.2797982096672058, 0.33920755982398987, 0.24281997978687286, 0.30163389444351196, 0.10508523881435394, 0.1483481079339981, 0.1926211416721344, 0.2674314081668854, 0.2501133680343628, 0.21725046634674072, 0.23169353604316711, 0.2080250233411789, 0.1887333244085312, 0.23553693294525146, 0.43771255016326904, 0.1736334264278412, 0.25808724761009216, 0.1973927766084671, 0.2525789141654968, 0.5791015028953552, 0.15770381689071655, 0.21012245118618011, 0.2694588601589203, 0.21160534024238586, 0.10750655084848404, 0.13922496140003204, 0.2066754698753357, 0.20600779354572296, 0.22226856648921967, 0.21738451719284058, 0.2772778868675232, 0.302903950214386, 0.25697171688079834, 0.3161168396472931, 0.23368287086486816, 0.251319944858551, 0.1872175931930542, 0.24666514992713928, 0.46055322885513306, 0.19696325063705444, 0.21202342212200165, 0.2612055540084839, 0.227860689163208, 0.2637646794319153, 0.29632294178009033, 0.36890971660614014, 0.14094986021518707, 0.19154027104377747, 0.3432762324810028, 0.23402592539787292, 0.3710688352584839, 0.27677470445632935, 0.10357566922903061, 0.19139759242534637, 0.3091796338558197, 0.40430569648742676, 0.3442494571208954, 0.1705738604068756, 0.19786672294139862, 0.09430212527513504, 0.4204443395137787, 0.3770174980163574, 0.10718098282814026, 0.23641163110733032, 0.18807803094387054, 0.3365485668182373, 0.15502741932868958, 0.31845200061798096, 0.3014104962348938, 0.32149842381477356, 0.17648817598819733, 0.1162542924284935, 0.2765653431415558, 0.20480892062187195, 0.12908676266670227, 0.21695175766944885, 0.2964199185371399, 0.25910213589668274, 0.3650689721107483, 0.12888804078102112, 0.1795291155576706, 0.34596753120422363, 0.09031341969966888, 0.42780202627182007, 0.19927512109279633, 0.3131198585033417, 0.11986994743347168, 0.2501124441623688, 0.3431206941604614, 0.49714893102645874, 0.1199301928281784, 0.12349376082420349, 0.10829515755176544, 0.18682439625263214, 0.1623792052268982, 0.178498312830925, 0.1609053909778595, 0.26339876651763916, 0.21331551671028137, 0.09586548060178757, 0.26842814683914185, 0.22926419973373413, 0.29945802688598633, 0.2562325596809387, 0.1796596646308899, 0.2820660173892975, 0.23051950335502625, 0.1857186257839203, 0.13111349940299988, 0.12665125727653503, 0.34674352407455444, 0.22347629070281982, 0.19822154939174652, 0.20263352990150452, 0.19234222173690796, 0.13789857923984528, 0.3347836434841156, 0.18753916025161743, 0.22083699703216553, 0.24305474758148193, 0.15541739761829376, 0.1549607217311859, 0.27054452896118164, 0.26895636320114136, 0.10553761571645737, 0.25255656242370605, 0.13435034453868866, 0.330030232667923, 0.08827745914459229, 0.21635447442531586, 0.2717679440975189, 0.1156831607222557, 0.18686039745807648, 0.24085643887519836, 0.38017383217811584, 0.10273668169975281, 0.17507581412792206, 0.14410872757434845, 0.13346633315086365, 0.15968069434165955, 0.1476222574710846, 0.16107654571533203, 0.06457740813493729, 0.2627967596054077, 0.1739915907382965, 0.2803422510623932, 0.11593417823314667, 0.23733699321746826, 0.1665840446949005, 0.2628118395805359, 0.38123518228530884, 0.14115433394908905, 0.24712933599948883, 0.2775973081588745, 0.1593439131975174, 0.4881601631641388, 0.15993694961071014, 0.22567963600158691, 0.24120256304740906, 0.442588746547699, 0.11117585748434067, 0.176674023270607, 0.10758370161056519, 0.14379946887493134, 0.14073875546455383, 0.0928429439663887, 0.27740782499313354, 0.22633396089076996, 0.38344818353652954, 0.38684317469596863, 0.19674743711948395, 0.08688117563724518, 0.12872296571731567, 0.4406581223011017, 0.2240477204322815, 0.3045932352542877, 0.182322695851326, 0.17029263079166412, 0.2202472984790802, 0.174057275056839, 0.16460207104682922, 0.2716526389122009, 0.18075568974018097, 0.3423194885253906, 0.37681981921195984, 0.16389170289039612, 0.20977850258350372, 0.10910143703222275, 0.0886065736413002, 0.26547500491142273, 0.5126852989196777, 0.1382424533367157, 0.31218719482421875, 0.24290037155151367, 0.1949852555990219, 0.29636478424072266, 0.16650712490081787, 0.14750239253044128, 0.25576716661453247, 0.1901862621307373, 0.2942851483821869, 0.31581389904022217, 0.2686827778816223, 0.26680541038513184, 0.1983640342950821, 0.08513756841421127, 0.11927836388349533, 0.18186751008033752, 0.10297902673482895, 0.30447399616241455, 0.3385825455188751, 0.18831166625022888, 0.35146814584732056, 0.2108505517244339, 0.30910247564315796, 0.2681097984313965, 0.1389317512512207, 0.11419975757598877, 0.2922672629356384, 0.12823177874088287, 0.18184217810630798, 0.10764512419700623, 0.13274115324020386, 0.3552559018135071, 0.28224021196365356, 0.1290607899427414, 0.2495226114988327, 0.2507063150405884, 0.22559012472629547, 0.1666789948940277, 0.1632908284664154, 0.16591289639472961, 0.1775939166545868, 0.2235666811466217, 0.20298480987548828, 0.22810682654380798, 0.22927051782608032, 0.2002289593219757, 0.23039917647838593, 0.12542501091957092, 0.07895008474588394, 0.052639998495578766, 0.1521584838628769, 0.11617346853017807, 0.31180667877197266, 0.10812196135520935, 0.30663150548934937, 0.215775728225708, 0.060309477150440216, 0.1508713662624359, 0.367918461561203, 0.3816213607788086, 0.307999849319458, 0.1054314523935318, 0.24921660125255585, 0.26877909898757935, 0.16074208915233612, 0.1430579274892807, 0.12561911344528198, 0.16044101119041443, 0.25108635425567627, 0.154861718416214, 0.20708364248275757, 0.4547416567802429, 0.11610628664493561, 0.23609080910682678, 0.13144226372241974, 0.1516634076833725, 0.12590119242668152, 0.1476382166147232, 0.14623036980628967, 0.12070950865745544, 0.11244450509548187, 0.23679444193840027, 0.10174469649791718, 0.16142365336418152, 0.1615068018436432, 0.13483881950378418, 0.14191961288452148, 0.2453417181968689, 0.2798873782157898, 0.33369961380958557, 0.12907561659812927, 0.3613009452819824, 0.20038875937461853, 0.38276493549346924, 0.2285199761390686, 0.07863258570432663, 0.16920773684978485, 0.39253363013267517, 0.12677434086799622, 0.11486645042896271, 0.17134693264961243, 0.11235867440700531, 0.17858177423477173, 0.11706101894378662, 0.18912960588932037, 0.25458723306655884, 0.21921700239181519, 0.08911599218845367, 0.2847062349319458, 0.30203691124916077, 0.23705123364925385, 0.1406460851430893, 0.31308868527412415, 0.3922540545463562, 0.19549737870693207, 0.06980963051319122, 0.07038889080286026, 0.13485464453697205, 0.15672850608825684, 0.17523866891860962, 0.2852433919906616, 0.2952303886413574, 0.039364829659461975, 0.16236189007759094, 0.3482452929019928, 0.21670164167881012, 0.25108879804611206, 0.202238529920578, 0.14367471635341644, 0.09748781472444534, 0.29200899600982666, 0.3507646918296814, 0.1605844348669052, 0.3126506507396698, 0.19645830988883972, 0.1749761402606964, 0.08923656493425369, 0.22474044561386108, 0.1610276699066162, 0.18930071592330933, 0.08332986384630203, 0.13007310032844543, 0.1543329507112503, 0.2672653794288635, 0.15729741752147675, 0.14878515899181366, 0.17494143545627594, 0.08447209000587463, 0.10483016818761826, 0.20077921450138092, 0.11439850926399231, 0.23606029152870178, 0.36237093806266785, 0.24266059696674347, 0.17638644576072693, 0.4115266501903534, 0.16229179501533508, 0.12838388979434967, 0.21953463554382324, 0.14555750787258148, 0.16560569405555725, 0.20611175894737244, 0.11012079566717148, 0.11644766479730606, 0.12004242837429047, 0.37730297446250916, 0.16816267371177673, 0.3452133238315582, 0.17792877554893494, 0.13002368807792664, 0.1272650957107544, 0.384910523891449, 0.2532840371131897, 0.2607988715171814, 0.11570347845554352, 0.21539941430091858, 0.17093637585639954, 0.27881625294685364, 0.18067213892936707, 0.2306196540594101, 0.38725897669792175, 0.272600382566452, 0.1624564230442047, 0.18594685196876526, 0.13031181693077087, 0.17481574416160583, 0.10969915986061096, 0.21180374920368195, 0.06330829858779907, 0.16189922392368317, 0.2329603135585785, 0.5245198607444763, 0.22667163610458374, 0.10000790655612946, 0.13338406383991241, 0.28832077980041504, 0.17493757605552673, 0.14386451244354248, 0.23030269145965576, 0.204300194978714, 0.17606408894062042, 0.14750894904136658, 0.08228308707475662, 0.1018664538860321, 0.20692041516304016, 0.12372007966041565, 0.10368970036506653, 0.1658720076084137, 0.11984224617481232, 0.3228088915348053, 0.17611739039421082, 0.19105736911296844, 0.07757280021905899, 0.3658151924610138, 0.0638115406036377, 0.29773378372192383, 0.14604929089546204, 0.2771189212799072, 0.2987583875656128, 0.26928266882896423, 0.12640777230262756, 0.21630141139030457, 0.06087959557771683, 0.12901023030281067, 0.2705864906311035, 0.23728640377521515, 0.140891894698143, 0.19483235478401184, 0.2578940987586975, 0.14693327248096466, 0.13480114936828613, 0.17656366527080536, 0.25172173976898193, 0.09025120735168457, 0.1432303935289383, 0.23373118042945862, 0.19776275753974915, 0.14649179577827454, 0.2709117531776428, 0.14615321159362793, 0.07016362249851227, 0.25976866483688354, 0.11206229031085968, 0.3109745979309082, 0.29181212186813354, 0.1484493911266327, 0.12523514032363892, 0.07493165135383606, 0.17708168923854828, 0.18591779470443726, 0.24579191207885742, 0.11832517385482788, 0.32131490111351013, 0.14221039414405823, 0.13792972266674042, 0.11767040193080902, 0.09464915841817856, 0.05619152635335922, 0.17018795013427734, 0.2611241936683655, 0.15478119254112244, 0.18915089964866638, 0.19915519654750824, 0.21804483234882355, 0.3118645250797272, 0.27147167921066284, 0.37463998794555664, 0.41418203711509705, 0.10838376730680466, 0.08150329440832138, 0.3656269907951355, 0.10897312313318253, 0.10346847772598267, 0.14136913418769836, 0.09283618628978729, 0.1661006659269333, 0.17451831698417664, 0.09187468886375427, 0.07392822206020355, 0.22866040468215942, 0.21787090599536896, 0.16335360705852509, 0.24456727504730225, 0.04411810636520386, 0.17276184260845184, 0.21392974257469177, 0.18515507876873016, 0.14267203211784363, 0.1666141301393509, 0.13598039746284485, 0.30199986696243286, 0.1586817055940628, 0.17684295773506165]}]}], \"run_logs\": \"\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": true, \"log_level\": \"INFO\", \"sdk_version\": \"1.0.72\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "ninhu"
   }
  ],
  "category": "training",
  "compute": [
   "AML Compute"
  ],
  "datasets": [
   "MNIST"
  ],
  "deployment": [
   "None"
  ],
  "exclude_from_index": false,
  "framework": [
   "PyTorch"
  ],
  "friendly_name": "Distributed PyTorch",
  "index_order": 1,
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "tags": [
   "None"
  ],
  "task": "Train a model using the distributed training via Horovod"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
